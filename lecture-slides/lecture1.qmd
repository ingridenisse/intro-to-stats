---
title: Introduction to Statistics - Young Researchers Fellowship Program
subtitle: Lecture 1 - Introduction to Statistics & Tabular Data Logic
institute: Laboratorio de Investigación para el Desarrollo del Ecuador
author: Daniel Sánchez Pazmiño
date: 2024-09-01
theme: berlin
date-format: "MMMM YYYY"
format: beamer
incremental: false
fontsize: 10pt
include-in-header:
    - text: |
        \setbeamercolor{background canvas}{bg=white}
        \setbeamertemplate{caption}[numbered]
        \usecolortheme[named=black]{structure}
        \usepackage{tikz}
        \usepackage{pgfplots}
knitr:
    opts_chunk: 
      echo: true
      message: false
      warning: false
---

```{r}
#| label: setup
#| include: false

library(readxl)
library(dplyr)
library(kableExtra)
library(readr)
library(here)
library(lubridate)
library(tidyr)
library

# Prelim data cleaning

# Load the SUPERCIAS dataset

# supercias_raw <- read_excel("data/directorio_companias_supercias.xlsx", skip = 4)

# supercias_raw <- supercias_raw %>%
    #janitor::clean_names() %>%
    #mutate(capital_suscrito = parse_number(capital_suscrito, 
                                           #locale = locale(decimal_mark = ",", grouping_mark = ".")))

#save(supercias_raw, file = "data/supercias_raw.RData")

# write_csv(supercias_raw, here("data/supercias_raw.csv"))

load(here("data/supercias_raw.RData"))

set.seed(123)

```

# What is statistics?

## What is statistics?

- A **methodology** for collecting, analyzing, interpreting, and presenting numerical information.

- A statistic is often referred to as a **numerical fact** or a **piece of data** which describes a particular characteristic of a group of individuals.
    - In the field of statistics, we typically don't refer to individual data points as statistics.

- In several fields, statistics is used as an aid to decision making under uncertainty.

- In a research context, statistics will be needed to understand phenomena, make predictions, and test hypotheses emerging from theory.

- *Statistics is the systematic investigation of the correspondence of theory with the real world*

# Data in statistics

## Data in statistics

- Because statistics is concerned with information, **data** is often the starting point of any statistical analysis.

- No clear definition of data can possibly satisfy everyone, but we can think of data as a collection of **facts** to be analyzed. 
    - Data is **plural** for **datum**.

- A **dataset** is a collection of data points, which can be organized in a **table**, often about a specific topic, purpose, experiment, study, or context.

## Broad types of data

- Typically, statistics makes a distinction between two broad types of data:

1. **Quantitative** data, which is numerical in nature, meaning it can be measured and expressed in numbers.
    - Discrete data: whole numbers (e.g., number of students in a class).
    - Continuous data: real numbers (e.g., height, weight).

2. **Categorical** or "qualitative" data, which is non-numerical in nature, meaning it cannot be directly measured or expressed in numbers. 
    - Nominal data: categories without order (e.g., colors).
    - Ordinal data: categories with order (e.g., levels of satisfaction).

## How a dataset might look like

```{r}
#| label: example-dataset-supercias
#| tbl-cap: Example dataset from the Ecuadorian Superintendencia de Compañías, Valores y Seguros (SUPERCIAS) companies' directory.
#| include: false

# Print random 5 rows, with 5 columns

supercias_raw %>%
  select("RUC" = ruc,
         "Fecha Constitucion" = fecha_constitucion,
         "Provincia" = provincia,
         "Capital Suscrito" = capital_suscrito) %>%
  sample_n(5) %>%
  kable()

```

- What type of data can be identified for each column in the dataset?

## Types of datasets

- Datasets can be classified into different types based on the nature of the data they contain.

1. **Cross-sectional data**: data collected at a single point in time.
    - Example: a survey conducted in 2024.

2. **Time series data**: data collected over time at regular intervals, for a single entity.a
    - Example: monthly sales data from 2020 to 2024.

3. **Panel data**: data collected over time for multiple entities.
    - Example: monthly sales data from 2020 to 2024 for multiple companies.

- Often, we also hear about repeated or pooled cross-sectional data, which is a combination of cross-sectional and time series data; we observe multiple cross-sections at different points in time.

# Tabular data logic

## Tabular data logic

- A dataset is typically organized in a **table** with rows and columns.

- Datasets often collect characteristics of individuals or entities, which are typically referred to as **elements**.
    - Elements are not necessarily the observations in a dataset, elements are those entities or individuals for which we hold information. 

- When data is *tidy*, a table structure typically allows for easy identification of the following elements:
    - We will talk more about **tidy data** concept in the R companion module.

1. **Variables**: columns in the table, which represent a characteristic of an element.
2. **Observations**: rows in the table, which represent a collection of variable values for a single element.

## Elements are not observations 

- Sometimes, elements in a dataset (for the SUPERCIAS dataset, companies) are not the same as observations.

- We may observe multiple observations for a single element, which is why we need to be clear about the distinction between elements and observations.

- When we observe multiple observations for a single element, we typically refer to this as **repeated measures** or **panel data**.

- It is in this context when it comes in handy to difference between long and wide format datasets.

## Long vs. wide format

- Long vs. wide format refers to the way data is organized in a table. 

- In the **long format**, each row represents a single observation, and each column represents a variable.

- In the **wide format**, each row typically represents a single element. Columns may represent variables, but also repeated measures or time points of the same variable. 

## Example of long vs. wide format - business creation per province

- Long format: each row represents a single observation (business creation per province per year).

```{r}
#| label: example-long-vs-wide
#| tbl-cap: Long format business creation per province (SUPERCIAS)
#| echo: false

supercias <-
    supercias_raw %>%
    mutate(creation_date = dmy(fecha_constitucion),
           year_creation = year(creation_date))

# Create a dataset with business creation per province

business_creation <- 
  supercias %>%
  mutate(creation_date = dmy(fecha_constitucion),
         year_creation = year(creation_date),
         ) %>%
  count(provincia, year_creation)

creation_show <-
    business_creation %>%
    filter(year_creation > 2009) %>% 
    sample_n(5) %>%
    transmute("Province" = provincia,
              "Year" = year_creation,
              "Number of businesses created" = n)

creation_show %>%
  kable()
```

- Notice that if a province creates businesses in multiple years, we will have multiple rows for the same province.

- If a province does not create businesses in a given year, we will not have a row for that province.

## Example of long vs. wide format - business creation per province

- Wide format: each row represents a single element (province), and columns represent variables (business creation per year).

```{r}
#| label: example-long-vs-wide-wide
#| tbl-cap: Wide format business creation per province (SUPERCIAS)
#| echo: false

# Create a dataset with business creation per province

creation_show %>%
  pivot_wider(names_from = Year, values_from = `Number of businesses created`) %>%
  kable()
```

- We will never have multiple rows for the same province in the wide format.

- If a province does not create businesses in a given year, we will have missing values.

# Sources of data

## Where do we get data for statistical analysis?

1. Experimental studies

2. Observational studies

3. Secondary sources (existing datasets)

# Descriptive statistics vs. statistical inference

## Descriptive statistics vs. statistical inference

- **Descriptive statistics** summarize and describe the main features of a dataset.
    - Descriptive statistics are used to describe the data as it is.
    - Examples: mean, median, mode, standard deviation, variance, etc.
    - Tables and visualizations are commonly used as well

- **Statistical inference** is the process of making predictions or inferences about a population based on a sample.
    - A population is the entire group of individuals or entities we are interested in.
    - A sample is a subset of the population.

## Why even care about descriptive statistics?

- Sometimes we do have the entire population data, but we still use descriptive statistics.
   - E.g. a small population such as this group of students.

- Sometimes gathering data from the entire population is not feasible, so we use a sample to make inferences about the population.

- Descriptive statistics should be first understood well before moving to statistical inference.
    - We later use descriptive statistics to summarize the sample data and make inferences about the population based on the sample statistics
    - We will require an understanding of probability theory to make inferences about the population with the descriptive statistics of the sample.

## Notation

- In statistics, we often use the following notation:

    - $n$: the number of observations in a dataset.
    - $x_i$: the $i$-th observation in a dataset.

- We often want to underscore the difference between a descriptive statistic calculated for a sample or a population.

    - For a sample, we use a lowercase letter to denote the statistic (e.g., $\overbar{x}$ for the sample mean). We call this a sample statistic.
    - For a population, we use a Greek letter to denote the statistic (e.g., $\mu$ for the population mean). We call this a population parameter.

- In the rest of these slides, I will use the sample notation for simplicity. We will later discuss the difference between sample statistics and population parameters as we move to statistical inference.

# Univariate descriptive statistics

## Univariate data

- **Univariate data** refers to data that consists of a single variable or attribute.

- We are interested in summarizing single variables in a dataset.

- We'll later discuss bivariate descriptive statistics, which summarize the relationship between two variables.

## Central tendency measures

Measures of central tendency are values that represent the center of a data set.

- **Mean**: the average of the data
- **Median**: the value that divides the data into two equal parts
- **Mode**: the value that appears most frequently

## The mean $\overbar{x}$

- The average or, more specifically, the **arithmetic mean** is the sum of all observations divided by the number of observations.
    - There are other types of means, such as the geometric mean, harmonic mean, etc.

$$ \overbar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i =  \dfrac{1}{n} \left(x_1 + x_2 + \ldots + x_n\right) $$

- The mean is sensitive to outliers, so use with caution.
    - Very large or very small values can make the mean less representative of a typical value in the dataset.

## Software implementation for the mean

- Use the base R function `mean()` to calculate the mean of a variable.

- You may need to use the `na.rm = TRUE` argument to remove missing values, depending on the dataset. 

```{r}
#| label: mean-calculation

# Calculate the mean of the capital suscrito variable

mean_capital_suscrito <- mean(supercias_raw$capital_suscrito, 
                              na.rm = TRUE)

mean_capital_suscrito

```

## Median

- The median is the value that divides the data into two equal parts.

- You must first sort the data from smallest to largest.
    - If the number of observations is odd, the median is the middle value.
    - If the number of observations is even, the median is the average of the two middle values.

- The median is less sensitive to outliers than the mean.
    - Typically, income data is reported using the median because it is less affected by extreme values.

$$ \text{Median} = \begin{cases} x_{(n+1)/2} & \text{if } n \text{ is odd} \\ \frac{1}{2} \left( x_{n/2} + x_{n/2 + 1} \right) & \text{if } n \text{ is even} \end{cases} $$

## Software implementation for the median

- Use the base R function `median()` to calculate the median of a variable.

- You may need to use the `na.rm = TRUE` argument to remove missing values, depending on the dataset.

```{r}
#| label: median-calculation

# Calculate the median of the capital suscrito variable

median_capital_suscrito <- median(supercias$capital_suscrito, 
                                  na.rm = TRUE)

median_capital_suscrito
```

## Mode

- The mode is the value that appears most frequently in the dataset.

- A dataset can have multiple modes if multiple values appear with the same frequency.

- The mode is not always defined, and it may not be unique.

- The mode is less commonly used than the mean and median.

## Software implementation for the mode

- There is no built-in function in base R to calculate the mode.

- You can look for a function in a package or use the `table()` function to count the frequency of each value, then find the maximum frequency.

```{r}
#| label: mode-calculation
#| results: hide

# Calculate the mode of the capital suscrito variable

mode_capital_suscrito <- table(supercias$capital_suscrito)
```

## Software implementation for the mode

```{r}
#| label: mode-calculation-2
#| echo: false

# Find the maximum frequency

kable(head(mode_capital_suscrito))
```

## Dispersion or variability measures

- **Dispersion** or **variability** measures describe how spread out the data is, or how much the data points differ from their central tendency.

- Common measures of dispersion include:
    - **Range**: the difference between the maximum and minimum values.
    - **Variance**: the average of the squared differences from the mean.
    - **Standard deviation**: the square root of the variance.
    - **Variation coefficient**: the standard deviation divided by the mean.

## Range

- The range is the difference between the maximum and minimum values in a dataset.

$$ \text{Range} = \text{Max} - \text{Min} $$

- The range is sensitive to outliers, so use with caution.

- Use `diff(range(x))` in R to calculate the range of a variable.
    - Use the `na.rm = TRUE` argument to remove missing values, depending on the dataset.
    - `range()` returns a vector with the minimum and maximum values, and `diff()` calculates the difference between them.

## Variance and standard deviation

- The variance is the average of the squared differences from the mean.

$$ s^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \overbar{x})^2 = \dfrac{1}{n} \left[ (x_1 - \overbar{x})^2 + (x_2 - \overbar{x})^2 + \ldots + (x_n - \overbar{x})^2 \right] $$

- The standard deviation is the square root of the variance.

$$ s = \sqrt{s^2} $$

- The standard deviation is in the same units as the data, unlike the variance.
    - The variance is squared, so it cannot be directly interpreted; higher variance means more spread out data, but not much else.

## Implementation in R

- Use the base R function `var()` to calculate the variance of a variable.

- Use the base R function `sd()` to calculate the standard deviation of a variable.

- You may need to use the `na.rm = TRUE` argument to remove missing values, depending on the dataset.

## Implementation in R

```{r}
#| label: variance-calculation

# Calculate the variance of the capital suscrito variable

range(supercias$capital_suscrito, na.rm = TRUE)

diff(range(supercias$capital_suscrito, na.rm = TRUE))

var(supercias$capital_suscrito, na.rm = TRUE)

sd(supercias$capital_suscrito, na.rm = TRUE)
```

## Coefficient of variation

- The coefficient of variation is the standard deviation divided by the mean.

$$ \text{CV} = \frac{s}{\overbar{x}} $$

- The coefficient of variation is a relative measure of dispersion.
    - It is useful when comparing the variability of two variables with different units or scales.

- The coefficient of variation is expressed as a percentage or a proportion (decimal).

- No direct function in R, but you can calculate it manually by dividing the standard deviation by the mean.

## Measures of position

- Measures of position describe the relative position of a data point within a dataset.

- Common measures of position include:
    - **Percentiles**: the value below which a given percentage of observations fall.
    - **Quartiles**: values that divide the data into four equal parts.
    - **Deciles**: values that divide the data into ten equal parts.
    - **Z-scores**: the number of standard deviations a data point is from the mean.

## Percentiles

- Percentiles are values below which a given percentage $p$ of observations fall.

- The $p$-th percentile is the value below which $p\%$ of the data fall.

- Again, we must first sort the data from smallest to largest before calculating percentiles. Then apply the formula:

$$ \text{Percentile}_p = \left( \frac{p}{100} \right) (n + 1) $$

- The median is the 50th percentile.

## Stata implementations

- You can get many of these statistics in Stata using the `summarize` command.
    - `summarize` will give you the mean, median, and other statistics for all variables in the dataset.
    - You can use the `detail` option to get more detailed statistics.

```stata
summarize capital_suscrito, detail
```

## Stata implementations

- You can also use the `summarize` command with the `meanonly` option to get only the mean.

- For the coefficient of variation, you can calculate it manually by dividing the standard deviation by the mean, using the `egen` command to create a new variable.

```stata
summarize capital_suscrito, meanonly
egen cv = sd(capital_suscrito) / mean(capital_suscrito)
```